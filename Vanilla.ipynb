{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83420a0b66a54a3899771a164f017d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_392ac41f23bd4eda99450ba64e9be2a7",
              "IPY_MODEL_18c7bca5d6a444509b8c928958a8a8f4"
            ],
            "layout": "IPY_MODEL_835184e3447e4789a6be06ac9f0cacef"
          }
        },
        "392ac41f23bd4eda99450ba64e9be2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d03173f06f49f8b4e9a58055c66490",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b85010f9f64b44b2ecd225f49fe6d6",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "18c7bca5d6a444509b8c928958a8a8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48200d1be2c4973b8f062c6e12040d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56cb025121f0474d836230f3532cf5de",
            "value": 1
          }
        },
        "835184e3447e4789a6be06ac9f0cacef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d03173f06f49f8b4e9a58055c66490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b85010f9f64b44b2ecd225f49fe6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a48200d1be2c4973b8f062c6e12040d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56cb025121f0474d836230f3532cf5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8193773,
          "sourceType": "datasetVersion",
          "datasetId": 4852942
        },
        {
          "sourceId": 8226678,
          "sourceType": "datasetVersion",
          "datasetId": 4878019
        },
        {
          "sourceId": 8226741,
          "sourceType": "datasetVersion",
          "datasetId": 4878064
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Gdrive"
      ],
      "metadata": {
        "id": "ycFKHnvUpjXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-R3PBLjkpf1X",
        "outputId": "64e6c7ef-0649-4050-9bdf-ee462847f90e",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:30.478042Z",
          "iopub.execute_input": "2024-04-30T17:50:30.478440Z",
          "iopub.status.idle": "2024-04-30T17:50:30.483671Z",
          "shell.execute_reply.started": "2024-04-30T17:50:30.478408Z",
          "shell.execute_reply": "2024-04-30T17:50:30.482613Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "JGOTcc5wyJA-",
        "outputId": "3b187839-8a56-4863-e2c3-e524bc263b2b",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:30.933597Z",
          "iopub.execute_input": "2024-04-30T17:50:30.933961Z",
          "iopub.status.idle": "2024-04-30T17:50:44.625722Z",
          "shell.execute_reply.started": "2024-04-30T17:50:30.933933Z",
          "shell.execute_reply": "2024-04-30T17:50:44.624609Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key='5157ae11e5d243722bc57912a56718dc8ef2f734') #Wandb login with my key\n",
        "# 5157ae11e5d243722bc57912a56718dc8ef2f734"
      ],
      "metadata": {
        "id": "t72ZPROsyJrt",
        "outputId": "b14d2386-79c1-40af-c836-3d9fd2181c12",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:44.627669Z",
          "iopub.execute_input": "2024-04-30T17:50:44.627967Z",
          "iopub.status.idle": "2024-04-30T17:50:47.855108Z",
          "shell.execute_reply.started": "2024-04-30T17:50:44.627940Z",
          "shell.execute_reply": "2024-04-30T17:50:47.854059Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "zN3UGNk9pcKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import unicodedata\n",
        "import string\n",
        "import copy"
      ],
      "metadata": {
        "id": "HWuEVwxzp7RN",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:47.856316Z",
          "iopub.execute_input": "2024-04-30T17:50:47.856830Z",
          "iopub.status.idle": "2024-04-30T17:50:51.577112Z",
          "shell.execute_reply.started": "2024-04-30T17:50:47.856803Z",
          "shell.execute_reply": "2024-04-30T17:50:51.576089Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "path = '/content/drive/MyDrive/DL/A3_DATA/aksharantar_sampled/hin'"
      ],
      "metadata": {
        "id": "tMpYfXaFYmni",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.579355Z",
          "iopub.execute_input": "2024-04-30T17:50:51.579836Z",
          "iopub.status.idle": "2024-04-30T17:50:51.584693Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.579811Z",
          "shell.execute_reply": "2024-04-30T17:50:51.583690Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for GPU"
      ],
      "metadata": {
        "id": "moRNj0BQpy4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "MPSuUeiJtXpO",
        "outputId": "e0eefdfb-6846-42ce-a42d-b7bd0ca897b7",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.586002Z",
          "iopub.execute_input": "2024-04-30T17:50:51.586323Z",
          "iopub.status.idle": "2024-04-30T17:50:51.641329Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.586288Z",
          "shell.execute_reply": "2024-04-30T17:50:51.640268Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "LeCpEPARiGue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "# Sort the list of CSV file paths alphabetically\n",
        "csv_files = sorted(csv_files)\n",
        "print(csv_files)"
      ],
      "metadata": {
        "id": "cum-SiSkqNUs",
        "outputId": "17923c50-517c-4e22-98b6-72c913271912",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.642523Z",
          "iopub.execute_input": "2024-04-30T17:50:51.642864Z",
          "iopub.status.idle": "2024-04-30T17:50:51.665543Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.642839Z",
          "shell.execute_reply": "2024-04-30T17:50:51.664586Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/DL/A3_DATA/aksharantar_sampled/hin/hin_test.csv', '/content/drive/MyDrive/DL/A3_DATA/aksharantar_sampled/hin/hin_train.csv', '/content/drive/MyDrive/DL/A3_DATA/aksharantar_sampled/hin/hin_valid.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=pd.read_csv(csv_files[0])\n",
        "train_data=pd.read_csv(csv_files[1])\n",
        "valid_data=pd.read_csv(csv_files[2])\n",
        "\n",
        "display((valid_data))"
      ],
      "metadata": {
        "id": "ayBGC6kkug2r",
        "outputId": "0facb103-c7d4-4eda-a983-65d03dbe333e",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.666795Z",
          "iopub.execute_input": "2024-04-30T17:50:51.667474Z",
          "iopub.status.idle": "2024-04-30T17:50:51.807858Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.667441Z",
          "shell.execute_reply": "2024-04-30T17:50:51.806746Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         jaisawal       जयसवाल\n",
              "0           bajai         बजाई\n",
              "1       sanghthan        संघठन\n",
              "2         haiwaan        हैवान\n",
              "3         nilgiri      नीलगिरि\n",
              "4       drutgrami  द्रुतग्रामी\n",
              "...           ...          ...\n",
              "4090     paranshu       परांशु\n",
              "4091    romanchit     रोमांचित\n",
              "4092  ekamreshwar  एकाम्रेश्वर\n",
              "4093    bluetooth    ब्ल्यूटूथ\n",
              "4094    govindram   गोविंद्राम\n",
              "\n",
              "[4095 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ad1d40-fe19-4cb7-974c-c5aefa20ecae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jaisawal</th>\n",
              "      <th>जयसवाल</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bajai</td>\n",
              "      <td>बजाई</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sanghthan</td>\n",
              "      <td>संघठन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>haiwaan</td>\n",
              "      <td>हैवान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nilgiri</td>\n",
              "      <td>नीलगिरि</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drutgrami</td>\n",
              "      <td>द्रुतग्रामी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4090</th>\n",
              "      <td>paranshu</td>\n",
              "      <td>परांशु</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>romanchit</td>\n",
              "      <td>रोमांचित</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>ekamreshwar</td>\n",
              "      <td>एकाम्रेश्वर</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>bluetooth</td>\n",
              "      <td>ब्ल्यूटूथ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>govindram</td>\n",
              "      <td>गोविंद्राम</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4095 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ad1d40-fe19-4cb7-974c-c5aefa20ecae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1ad1d40-fe19-4cb7-974c-c5aefa20ecae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1ad1d40-fe19-4cb7-974c-c5aefa20ecae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ca18c6d-e694-4614-afd1-c75b1448dd2d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ca18c6d-e694-4614-afd1-c75b1448dd2d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ca18c6d-e694-4614-afd1-c75b1448dd2d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bbbc573d-57dc-445f-9538-0a2e7957f683\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('valid_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bbbc573d-57dc-445f-9538-0a2e7957f683 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('valid_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "valid_data",
              "summary": "{\n  \"name\": \"valid_data\",\n  \"rows\": 4095,\n  \"fields\": [\n    {\n      \"column\": \"jaisawal\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4075,\n        \"samples\": [\n          \"yularvaad\",\n          \"ketubuddin\",\n          \"naraynasamy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u091c\\u092f\\u0938\\u0935\\u093e\\u0932\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3245,\n        \"samples\": [\n          \"\\u092e\\u0948\\u0915\\u0932\\u0942\\u0939\\u093e\\u0928\",\n          \"\\u0915\\u0941\\u0930\\u093f\\u0928\\u094d\\u0925\\u093f\\u092f\\u094b\\u0902\",\n          \"\\u0924\\u0947\\u091c\\u0938\\u094d\\u0935\\u0940\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "A_zudZa061o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionary  index =>character and character => index"
      ],
      "metadata": {
        "id": "Ewnfh--ArVIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data path\n",
        "train_data_path=csv_files[1]\n",
        "\n",
        "# Load the CSV file using pandas\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Assuming the CSV file has two columns named 'source' and 'target'\n",
        "# Extract the first row to determine the column names dynamically\n",
        "first_row = train_data.iloc[0]\n",
        "\n",
        "# Determine the column names dynamically\n",
        "training_src = first_row.index[0]  # Assuming the first column is the source column\n",
        "training_target = first_row.index[1]  # Assuming the second column is the target column\n",
        "\n",
        "# Print the determined column names\n",
        "print(\"Source Column:\", training_src)\n",
        "print(\"Target Column:\", training_target)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.809280Z",
          "iopub.execute_input": "2024-04-30T17:50:51.809661Z",
          "iopub.status.idle": "2024-04-30T17:50:51.894980Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.809632Z",
          "shell.execute_reply": "2024-04-30T17:50:51.894102Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU-EbAlob_nw",
        "outputId": "1468c094-0813-4576-f871-e60c40119f0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Column: shastragaar\n",
            "Target Column: शस्त्रागार\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data path\n",
        "test_data_path=csv_files[0]\n",
        "\n",
        "# Load the CSV file using pandas\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming the CSV file has two columns named 'source' and 'target'\n",
        "# Extract the first row to determine the column names dynamically\n",
        "first_row = test_data.iloc[0]\n",
        "\n",
        "# Determine the column names dynamically\n",
        "test_src = first_row.index[0]  # Assuming the first column is the source column\n",
        "test_target = first_row.index[1]  # Assuming the second column is the target column\n",
        "\n",
        "# Print the determined column names\n",
        "print(\"Source Column:\", test_src)\n",
        "print(\"Target Column:\", test_target)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.895924Z",
          "iopub.execute_input": "2024-04-30T17:50:51.896193Z",
          "iopub.status.idle": "2024-04-30T17:50:51.910724Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.896170Z",
          "shell.execute_reply": "2024-04-30T17:50:51.909759Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgwfUsuvb_nw",
        "outputId": "f8b5b142-b57b-4375-cc1d-6ebce324abde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Column: thermax\n",
            "Target Column: थरमैक्स\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assume we want to process the first CSV file in the list\n",
        "valid_data_path = csv_files[2]\n",
        "\n",
        "# Load the CSV file using pandas\n",
        "valid_data = pd.read_csv(valid_data_path)\n",
        "\n",
        "# Assuming the CSV file has two columns named 'source' and 'target'\n",
        "# Extract the first row to determine the column names dynamically\n",
        "first_row = valid_data.iloc[0]\n",
        "\n",
        "# Determine the column names dynamically\n",
        "validation_src = first_row.index[0]  # Assuming the first column is the source column\n",
        "validation_target = first_row.index[1]  # Assuming the second column is the target column\n",
        "\n",
        "# Print the determined column names\n",
        "print(\"Source Column:\", validation_src)\n",
        "print(\"Target Column:\", validation_target)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.914428Z",
          "iopub.execute_input": "2024-04-30T17:50:51.915412Z",
          "iopub.status.idle": "2024-04-30T17:50:51.931252Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.915381Z",
          "shell.execute_reply": "2024-04-30T17:50:51.930330Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM_AIzHDb_nw",
        "outputId": "bed17403-32ec-462b-8fbe-e0bc490df09f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Column: jaisawal\n",
            "Target Column: जयसवाल\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prep-rocessing data"
      ],
      "metadata": {
        "id": "oCIgY7M1r2Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text conversion to Lowercase\n",
        "train_data[training_src] = train_data[training_src].str.lower()\n",
        "test_data[test_src]=test_data[test_src].str.lower()\n",
        "print(train_data[training_src].shape)\n",
        "print(test_data[test_src].shape)"
      ],
      "metadata": {
        "id": "YTmdFvyDr1Zv",
        "outputId": "f9526358-ee5b-43dc-86ad-c848085129aa",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.932463Z",
          "iopub.execute_input": "2024-04-30T17:50:51.932825Z",
          "iopub.status.idle": "2024-04-30T17:50:51.952780Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.932788Z",
          "shell.execute_reply": "2024-04-30T17:50:51.951668Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51199,)\n",
            "(4095,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning"
      ],
      "metadata": {
        "id": "TkBTpVEDsYxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning(text):\n",
        "    my_text=text\n",
        "    my_text = re.sub(r'[^\\u0900-\\u097F\\s]', '', text) # Remove punctuations and digits\n",
        "    my_text = re.sub(r'[\\d]', '', my_text)\n",
        "    target_vocab_size=58\n",
        "    my_text = unicodedata.normalize('NFD', my_text)  # Normalize text\n",
        "    my_text = ''.join(c for c in my_text if unicodedata.category(c) != 'Mn')\n",
        "    text2=0\n",
        "    my_text = unicodedata.normalize('NFC', my_text)\n",
        "    return my_text"
      ],
      "metadata": {
        "id": "VPCgxRWTsbym",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:51.954142Z",
          "iopub.execute_input": "2024-04-30T17:50:51.954533Z",
          "iopub.status.idle": "2024-04-30T17:50:51.961822Z",
          "shell.execute_reply.started": "2024-04-30T17:50:51.954495Z",
          "shell.execute_reply": "2024-04-30T17:50:51.960750Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing Train data"
      ],
      "metadata": {
        "id": "z7jEhnxUtjuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[training_target] = train_data[training_target].apply(data_cleaning)\n",
        "train_char_scr = set()\n",
        "train_char_target = set()\n",
        "for src, target in zip(train_data[training_src], train_data[training_target]):\n",
        "    train_char_scr.update(src)\n",
        "    train_char_target.update(target)\n",
        "\n",
        "train_char_scr = sorted(list(train_char_scr))\n",
        "train_char_target = sorted(list(train_char_target))\n"
      ],
      "metadata": {
        "id": "FBc8NCOXtn-F",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:52.440625Z",
          "iopub.execute_input": "2024-04-30T17:50:52.440971Z",
          "iopub.status.idle": "2024-04-30T17:50:52.522160Z",
          "shell.execute_reply.started": "2024-04-30T17:50:52.440942Z",
          "shell.execute_reply": "2024-04-30T17:50:52.521096Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing Test data"
      ],
      "metadata": {
        "id": "nMZP4deutovN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[test_target]=test_data[test_target].apply(data_cleaning)\n",
        "test_char_scr = set()\n",
        "test_char_target = set()\n",
        "for src, target in zip(test_data[test_src],test_data[test_target]):\n",
        "    test_char_scr.update(src)\n",
        "    test_char_target.update(target)\n",
        "test_char_scr = sorted(list(test_char_scr))\n",
        "test_char_target = sorted(list(test_char_target))\n"
      ],
      "metadata": {
        "id": "UIA4lnHXtrLN",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:52.523405Z",
          "iopub.execute_input": "2024-04-30T17:50:52.523744Z",
          "iopub.status.idle": "2024-04-30T17:50:52.536098Z",
          "shell.execute_reply.started": "2024-04-30T17:50:52.523715Z",
          "shell.execute_reply": "2024-04-30T17:50:52.535153Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing Valid data"
      ],
      "metadata": {
        "id": "n4kNC_Hxt2uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data[validation_target]=valid_data[validation_target].apply(data_cleaning)\n",
        "val_char_scr = set()\n",
        "print(\"A\",test_char_target)\n",
        "val_char_target = set()\n",
        "for src, target in zip(valid_data[validation_src], valid_data[validation_target]):\n",
        "    val_char_scr.update(src)\n",
        "    val_char_target.update(target)\n",
        "val_char_scr = sorted(list(val_char_scr))\n",
        "print((train_char_target))\n",
        "val_char_target = sorted(list(val_char_target))\n"
      ],
      "metadata": {
        "id": "Un49CmtKt6Hn",
        "outputId": "329036f2-2c46-427d-b5e3-aeb980faf369",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:52.537769Z",
          "iopub.execute_input": "2024-04-30T17:50:52.538124Z",
          "iopub.status.idle": "2024-04-30T17:50:52.549867Z",
          "shell.execute_reply.started": "2024-04-30T17:50:52.538092Z",
          "shell.execute_reply": "2024-04-30T17:50:52.548990Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A ['ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', 'ऽ', 'ा', 'ि', 'ी', 'ॉ', 'ॊ', 'ो', 'ौ']\n",
            "['ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', 'ऽ', 'ा', 'ि', 'ी', 'ॉ', 'ो', 'ौ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###character to index dictionary\n",
        "cha_src=sorted(list(set().union(train_char_scr,test_char_scr,val_char_scr)))\n",
        "print(train_data)\n",
        "cha_target=sorted(list(set().union(train_char_target,test_char_target,val_char_target )))\n",
        "\n",
        "char_to_index_src = {char: i for i, char in enumerate(cha_src)}\n",
        "len1 = len(char_to_index_src)\n",
        "char_to_index_target = {char: i for i, char in enumerate(cha_target)}\n",
        "len2=len(char_to_index_target)\n",
        "char_to_index_src['<SOS>'] = len1\n",
        "char_to_index_target['<SOS>'] = len2\n",
        "len3= len(char_to_index_src)\n",
        "char_to_index_src['<EOS>'] =len3\n",
        "len4=len(char_to_index_target)\n",
        "char_to_index_target['<EOS>'] = len4\n",
        "len5=len(char_to_index_src)\n",
        "char_to_index_src['<PAD>'] = len5\n",
        "len6=len(char_to_index_target)\n",
        "char_to_index_target['<PAD>'] = len6\n",
        "print(char_to_index_target)\n",
        "\n",
        "## index to charcter dicitonary\n",
        "index_to_char_src={i:char for i,char in enumerate(cha_src)}\n",
        "print(char_to_index_src)\n",
        "index_to_char_target={i:char for i,char in enumerate(cha_target)}"
      ],
      "metadata": {
        "id": "14sCv2YUywJl",
        "outputId": "914f6df2-d6bc-4ea3-c68d-3ebb797a5755",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:52.550914Z",
          "iopub.execute_input": "2024-04-30T17:50:52.551241Z",
          "iopub.status.idle": "2024-04-30T17:50:52.565382Z",
          "shell.execute_reply.started": "2024-04-30T17:50:52.551217Z",
          "shell.execute_reply": "2024-04-30T17:50:52.564341Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       shastragaar शस्त्रागार\n",
            "0          bindhya     बिनदया\n",
            "1        kirankant    किरणकात\n",
            "2      yagyopaveet   यजञोपवीत\n",
            "3          ratania    रटानिया\n",
            "4       vaganyache    वागणयाच\n",
            "...            ...        ...\n",
            "51194        toned        टोड\n",
            "51195   mutanaazaa     मतनाजा\n",
            "51196    asahmaton     असहमतो\n",
            "51197    sulgaayin     सलगायी\n",
            "51198  anchuthengu       अचतग\n",
            "\n",
            "[51199 rows x 2 columns]\n",
            "{'ः': 0, 'अ': 1, 'आ': 2, 'इ': 3, 'ई': 4, 'उ': 5, 'ऊ': 6, 'ऋ': 7, 'ए': 8, 'ऐ': 9, 'ऑ': 10, 'ओ': 11, 'औ': 12, 'क': 13, 'ख': 14, 'ग': 15, 'घ': 16, 'ङ': 17, 'च': 18, 'छ': 19, 'ज': 20, 'झ': 21, 'ञ': 22, 'ट': 23, 'ठ': 24, 'ड': 25, 'ढ': 26, 'ण': 27, 'त': 28, 'थ': 29, 'द': 30, 'ध': 31, 'न': 32, 'प': 33, 'फ': 34, 'ब': 35, 'भ': 36, 'म': 37, 'य': 38, 'र': 39, 'ल': 40, 'ळ': 41, 'व': 42, 'श': 43, 'ष': 44, 'स': 45, 'ह': 46, 'ऽ': 47, 'ा': 48, 'ि': 49, 'ी': 50, 'ॉ': 51, 'ॊ': 52, 'ो': 53, 'ौ': 54, '<SOS>': 55, '<EOS>': 56, '<PAD>': 57}\n",
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '<SOS>': 26, '<EOS>': 27, '<PAD>': 28}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token(src,target,path): #source: input column of csv file , target: target column of csv file\n",
        "\n",
        "    data=pd.read_csv(path)\n",
        "    data_val = [] # char to num val\n",
        "    data[src] = data[src].str.lower()  # lowercase conversion of data\n",
        "    data[target] = data[target].apply(data_cleaning)\n",
        "\n",
        "    for src, targ in zip(data[src], data[target]):\n",
        "        source_val = [char_to_index_src[char] for char in src]\n",
        "        temp1=[char_to_index_src['<EOS>']]\n",
        "        source_val=[char_to_index_src['<SOS>']] + temp1 + source_val + [char_to_index_src['<PAD>']] * (28-len(src)-2)\n",
        "        target_val = [char_to_index_target[char] for char in targ]\n",
        "        temp2=target_val+[char_to_index_target['<EOS>']]\n",
        "        target_val=[char_to_index_target['<SOS>']]+temp2+[char_to_index_target['<PAD>']]*(20-len(targ)-2)\n",
        "        data_val.append([source_val, target_val])\n",
        "\n",
        "    return data_val"
      ],
      "metadata": {
        "id": "gJtRyjUjuvUZ",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:52.566818Z",
          "iopub.execute_input": "2024-04-30T17:50:52.567384Z",
          "iopub.status.idle": "2024-04-30T17:50:52.577552Z",
          "shell.execute_reply.started": "2024-04-30T17:50:52.567353Z",
          "shell.execute_reply": "2024-04-30T17:50:52.576711Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class AksharantarDataset is for making tokenized data iteratable"
      ],
      "metadata": {
        "id": "fdnwswpCj2Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_preprocess(Dataset):\n",
        "    def __init__(self, data):\n",
        "        \"\"\"\n",
        "        Initialize the dataset with the provided data.\n",
        "\n",
        "        Args:\n",
        "            data (list): List of tuples containing source and target data.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the total number of samples in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: Total number of samples.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ind_=0\n",
        "        \"\"\"\n",
        "        Retrieve a specific sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Tuple containing the source tensor and target tensor.\n",
        "        \"\"\"\n",
        "        src, target = self.data[index]\n",
        "        ind_=ind_+1\n",
        "        src_tensor = torch.tensor(src, dtype=torch.long)\n",
        "        target_tensor = torch.tensor(target, dtype=torch.long)\n",
        "        return src_tensor, target_tensor"
      ],
      "metadata": {
        "id": "lKSTqi8GvCP_",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:52.578613Z",
          "iopub.execute_input": "2024-04-30T17:50:52.578913Z",
          "iopub.status.idle": "2024-04-30T17:50:52.588534Z",
          "shell.execute_reply.started": "2024-04-30T17:50:52.578878Z",
          "shell.execute_reply": "2024-04-30T17:50:52.587672Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloading"
      ],
      "metadata": {
        "id": "r3esjDOVkUcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train=DataLoader(data_preprocess(generate_token(training_src,training_target,train_data_path)), batch_size=64, shuffle=True)\n",
        "data_val=DataLoader(data_preprocess(generate_token(validation_src,validation_target,valid_data_path)), batch_size=64, shuffle=False)\n",
        "data_test=DataLoader(data_preprocess(generate_token(test_src,test_target,test_data_path)), batch_size=64, shuffle=False)\n",
        "print(len(data_train))\n",
        "print(len(data_val))\n",
        "print(len(data_test))"
      ],
      "metadata": {
        "id": "Nd2sTFKRvylq",
        "outputId": "afe5f1ff-0e2d-4c4f-8031-45ba5c550288",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:50:59.749597Z",
          "iopub.execute_input": "2024-04-30T17:50:59.750286Z",
          "iopub.status.idle": "2024-04-30T17:51:00.880731Z",
          "shell.execute_reply.started": "2024-04-30T17:50:59.750254Z",
          "shell.execute_reply": "2024-04-30T17:51:00.879741Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "64\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "CQ_s_RxwkgfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters used:\n",
        "     # input embedding size => length of input to encoder\n",
        "     # embedding size => embedding length for each character in embedding layer\n",
        "     # hidden layer size => hidden size of encoder hidden states\n",
        "     # number of encoder layers => number of encoder layer in encoder\n",
        "     # dropout => dropout ratio appied in fc layer\n",
        "     # bidirectional => [True,False]\n",
        "     # cell type => 'LSTM','RNN','GRU'\n"
      ],
      "metadata": {
        "id": "lVeUpjHoyqCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "9c07PMuUx6N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "forward propogation for encoder"
      ],
      "metadata": {
        "id": "htrI-nGIdRcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_encoder(num_encoder_layer, hidden_size, bidirection, cell_type, embedding, rnn, dropout, inputs):\n",
        "    # Determine device (assuming 'device' is defined elsewhere)\n",
        "    device = inputs.device\n",
        "\n",
        "    # Initialize initial hidden states based on bidirection and cell_type\n",
        "    if bidirection:\n",
        "        num_directions = 2\n",
        "    else:\n",
        "        num_directions = 1\n",
        "\n",
        "    num_layers = num_encoder_layer * num_directions\n",
        "\n",
        "    if cell_type == 'LSTM':\n",
        "        h0 = torch.randn(num_layers, inputs.shape[0], hidden_size).to(device)\n",
        "        c0 = torch.randn(num_layers, inputs.shape[0], hidden_size).to(device)\n",
        "        initial_state = (h0, c0)\n",
        "    else:\n",
        "        h0 = torch.randn(num_layers, inputs.shape[0], hidden_size).to(device)\n",
        "        initial_state = h0\n",
        "\n",
        "    # Apply dropout to the input embeddings\n",
        "    embedded_inputs = dropout(embedding(inputs))\n",
        "    embedded_inputs = embedded_inputs.permute(1, 0, 2)  # Change input shape for RNN\n",
        "\n",
        "    # Forward pass through RNN\n",
        "    if cell_type == 'LSTM':\n",
        "        output, (hidden, cell) = rnn(embedded_inputs, initial_state)\n",
        "        return hidden, cell\n",
        "    else:\n",
        "        output, hidden = rnn(embedded_inputs, initial_state)\n",
        "        #cell = None  # No cell state for non-LSTM RNNs\n",
        "        return hidden, None\n"
      ],
      "metadata": {
        "id": "iXptx1BHc_eT",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:00.882180Z",
          "iopub.execute_input": "2024-04-30T17:51:00.882494Z",
          "iopub.status.idle": "2024-04-30T17:51:00.891357Z",
          "shell.execute_reply.started": "2024-04-30T17:51:00.882468Z",
          "shell.execute_reply": "2024-04-30T17:51:00.890310Z"
        },
        "trusted": true
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_decoder(embedding, rnn, dropout, fc, cell_type, x, hidden, cell):\n",
        "    # Prepare input tensor for the decoder\n",
        "    x = x.unsqueeze(0)\n",
        "    embedded_input = dropout(embedding(x))\n",
        "\n",
        "    if cell_type == 'LSTM':\n",
        "        # Apply the LSTM decoder with cell state\n",
        "        output, (hidden, cell) = rnn(embedded_input, (hidden, cell))\n",
        "    else:\n",
        "        # Apply the GRU or RNN decoder without cell state\n",
        "        output, hidden = rnn(embedded_input, hidden)\n",
        "        cell = None  # Set cell to None for consistency\n",
        "\n",
        "    # Perform fully connected layer operation for prediction\n",
        "    prediction = fc(output)\n",
        "    prediction = prediction.squeeze(0)  # Remove the extra dimension\n",
        "\n",
        "    return prediction, hidden, cell\n"
      ],
      "metadata": {
        "id": "DysDE-UwmEsS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self,input_size,embedding_size,hidden_size,num_encoder_layer,dropout,input_vocab_size,bidirection,cell_type):\n",
        "        super(encoder,self).__init__()\n",
        "\n",
        "        self.cell_type=cell_type\n",
        "        rnn_dict = {\n",
        "        'GRU': nn.GRU,\n",
        "        'RNN': nn.RNN,\n",
        "        'LSTM': nn.LSTM\n",
        "        }\n",
        "        self.num_encoder_layer=num_encoder_layer\n",
        "        self.embedding=nn.Embedding(input_vocab_size,embedding_size)\n",
        "        # Determine the RNN class based on the specified cell_type\n",
        "        rnn_class = rnn_dict[cell_type]\n",
        "        self.bidirection=bidirection    #self.embedding_size = embeddings_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.input_size = input_size\n",
        "\n",
        "\n",
        "    # Validate the cell_type\n",
        "        if cell_type not in rnn_dict:\n",
        "            raise ValueError(f\"Invalid cell_type: {cell_type}. Supported types are {list(rnn_dict.keys())}\")\n",
        "\n",
        "\n",
        "    # Check if num_encoder_layer is not equal to 1 to include dropout and bidirectional\n",
        "        if num_encoder_layer != 1:\n",
        "            self.rnn = rnn_class(embedding_size, hidden_size, num_encoder_layer,dropout=dropout, bidirectional=bidirection)\n",
        "        else:\n",
        "            self.rnn = rnn_class(embedding_size, hidden_size, num_encoder_layer,bidirectional=bidirection)\n",
        "\n",
        "\n",
        "    def forward(self,inputs):\n",
        "        return forward_encoder(self.num_encoder_layer ,self.hidden_size,self.bidirection,self.cell_type ,self.embedding,self.rnn , self.dropout , inputs  )\n"
      ],
      "metadata": {
        "id": "aJfIjpi2x8Ax",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:01.206586Z",
          "iopub.execute_input": "2024-04-30T17:51:01.207481Z",
          "iopub.status.idle": "2024-04-30T17:51:01.217230Z",
          "shell.execute_reply.started": "2024-04-30T17:51:01.207448Z",
          "shell.execute_reply": "2024-04-30T17:51:01.216284Z"
        },
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder"
      ],
      "metadata": {
        "id": "-tPAlrQ_x89z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "forward propogation for decoder"
      ],
      "metadata": {
        "id": "tQS9bMR02Gzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,input_size,embedding_size,hidden_size,output_vocab_size,num_decoder_layer,dropout,bidirection,cell_type):\n",
        "\n",
        "        super(Decoder,self).__init__()\n",
        "        self.cell_type=cell_type\n",
        "        self.embedding=nn.Embedding(output_vocab_size+3,embedding_size)\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "        self.num_decoder_layer=num_decoder_layer\n",
        "        self.hidden_size=hidden_size\n",
        "\n",
        "        rnn_dict = {\n",
        "            'GRU': nn.GRU,\n",
        "            'RNN': nn.RNN,\n",
        "            'LSTM': nn.LSTM\n",
        "        }\n",
        "\n",
        "        # Validate the cell_type\n",
        "        if cell_type not in rnn_dict:\n",
        "            raise ValueError(f\"Invalid cell_type: {cell_type}. Supported types are {list(rnn_dict.keys())}\")\n",
        "\n",
        "        # Determine the RNN class based on the specified cell_type\n",
        "        rnn_class = rnn_dict[cell_type]\n",
        "\n",
        "        # Check if num_encoder_layer is not equal to 1 to include dropout and bidirectional\n",
        "        if num_decoder_layer != 1:\n",
        "            rnn_class = rnn_dict[cell_type]\n",
        "            self.rnn = rnn_class(embedding_size, hidden_size, num_decoder_layer,dropout=dropout, bidirectional=bidirection)\n",
        "        else:\n",
        "            rnn_class = rnn_dict[cell_type]\n",
        "            self.rnn = rnn_class(embedding_size, hidden_size, num_decoder_layer,bidirectional=bidirection)\n",
        "\n",
        "        # bidirectional if used\n",
        "        if bidirection:\n",
        "            temp1=output_vocab_size+3\n",
        "            temp2=hidden_size*2\n",
        "            self.fc=nn.Linear(temp2,temp1)\n",
        "\n",
        "        else:\n",
        "            temp3=output_vocab_size+3\n",
        "            self.fc=nn.Linear(hidden_size,temp3)\n",
        "\n",
        "\n",
        "    def forward(self,x,hidden,cell):\n",
        "        return forward_decoder(self.embedding , self.rnn , self.dropout , self.fc , self.cell_type , x,hidden,cell)"
      ],
      "metadata": {
        "id": "QpsTYsY7wEm6",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:01.335654Z",
          "iopub.execute_input": "2024-04-30T17:51:01.335984Z",
          "iopub.status.idle": "2024-04-30T17:51:01.346502Z",
          "shell.execute_reply.started": "2024-04-30T17:51:01.335959Z",
          "shell.execute_reply": "2024-04-30T17:51:01.345543Z"
        },
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2seq model : connecting encoder and decoder to generate the output"
      ],
      "metadata": {
        "id": "Ulv7u-jnyDj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seq(nn.Module):\n",
        "    def __init__(self,encoder,decoder):\n",
        "        super(seq2seq,self).__init__()\n",
        "        self.encoder=encoder\n",
        "        target_vocab_size=58\n",
        "        self.decoder=decoder\n",
        "\n",
        "  #forward propogation\n",
        "    def forward(self,source,target,teacher_forceing=0.5):\n",
        "        self.target=target\n",
        "        batch_size=source.shape[0]\n",
        "        target_vocab_size=58\n",
        "        self.target_len=target.shape[1]\n",
        "\n",
        "        outputs=torch.zeros(self.target_len,batch_size,target_vocab_size).to(device)\n",
        "\n",
        "        hidden,cell=self.encoder(source)\n",
        "        x=target[:,0]\n",
        "\n",
        "\n",
        "        for t in range(0,self.target_len):\n",
        "            pred,hidden,cell=self.decoder(x,hidden,cell)\n",
        "            outputs[t]=pred\n",
        "            target_vocab_size=58\n",
        "            best_guess=pred.argmax(1)\n",
        "            target_vocab_size=58\n",
        "            x=target[:,t] if random.random()<teacher_forceing else best_guess\n",
        "        return outputs\n",
        "\n",
        "\n",
        "    def prediction(self,sources):\n",
        "        outputs=torch.zeros(self.target_len,sources.shape[0],58).to(device)\n",
        "        hidden,cell=self.encoder(sources)\n",
        "        x=sources[:,0]\n",
        "\n",
        "\n",
        "        for t in range(0,self.target_len):\n",
        "\n",
        "            pred,hidden,cell=self.decoder(x,hidden,cell)\n",
        "            outputs[t]=pred\n",
        "            target_vocab_size=58\n",
        "            best_guess=pred.argmax(1)\n",
        "            x=best_guess\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "uPFwnfazyCoG",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:01.456059Z",
          "iopub.execute_input": "2024-04-30T17:51:01.456331Z",
          "iopub.status.idle": "2024-04-30T17:51:01.467678Z",
          "shell.execute_reply.started": "2024-04-30T17:51:01.456309Z",
          "shell.execute_reply": "2024-04-30T17:51:01.466717Z"
        },
        "trusted": true
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sweep configuration over Hyperparameters"
      ],
      "metadata": {
        "id": "kiBSw3prrGxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_configuration={\n",
        "\n",
        "    'name':'cs23m013',\n",
        "    'method':'bayes',\n",
        "    'metric':{'name':'val_acc','goal':'maximize'},\n",
        "    'parameters':{\n",
        "\n",
        "        'epochs':{\n",
        "            'values':[1]\n",
        "        },\n",
        "\n",
        "         'learning_rate':{\n",
        "            'values':[0.001 , 0.0001 , 0.00001]\n",
        "        },\n",
        "\n",
        "        'embedding_size':{\n",
        "            'values':[64,128,256]\n",
        "            },\n",
        "\n",
        "        'num_encoder_layer':{\n",
        "            'values':[1,2,3]\n",
        "            },\n",
        "\n",
        "        'num_decoder_layer':{\n",
        "            'values':[1,2,3]\n",
        "        },\n",
        "\n",
        "        'hidden_layer_size':{\n",
        "            'values':[64,128 , 256,512]\n",
        "            },\n",
        "\n",
        "        'cell_type':{\n",
        "            'values':['LSTM','GRU', 'RNN']\n",
        "            },\n",
        "\n",
        "        'dropout':{\n",
        "            'values':[0, 0.2,0.3 , 0.4 , 0.6]\n",
        "            },\n",
        "\n",
        "        'bidirection':{\n",
        "            'values':[True,False]\n",
        "            }\n",
        "\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "FiIDeAzW34el",
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:01.514109Z",
          "iopub.execute_input": "2024-04-30T17:51:01.515006Z",
          "iopub.status.idle": "2024-04-30T17:51:01.522354Z",
          "shell.execute_reply.started": "2024-04-30T17:51:01.514975Z",
          "shell.execute_reply": "2024-04-30T17:51:01.521295Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "6iJfuQax3-j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_wandb():\n",
        "    wandb.init()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:01.584774Z",
          "iopub.execute_input": "2024-04-30T17:51:01.585058Z",
          "iopub.status.idle": "2024-04-30T17:51:01.589402Z",
          "shell.execute_reply.started": "2024-04-30T17:51:01.585034Z",
          "shell.execute_reply": "2024-04-30T17:51:01.588392Z"
        },
        "trusted": true,
        "id": "hKiH3-Ayb_n1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call Sweep"
      ],
      "metadata": {
        "id": "cfQlDDvtb_n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print and wandb log\n",
        "def wandb_log_final(train_accuracy_char ,  train_loss , val_accuracy_word,val_loss):\n",
        "    wandb.log({\n",
        "        'train_accuracy_char': train_accuracy_char,\n",
        "        'train_loss': train_loss,\n",
        "        'val_accuracy_word': val_accuracy_word,\n",
        "        'val_loss': val_loss\n",
        "    })\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:07.248783Z",
          "iopub.execute_input": "2024-04-30T17:51:07.249156Z",
          "iopub.status.idle": "2024-04-30T17:51:07.254995Z",
          "shell.execute_reply.started": "2024-04-30T17:51:07.249129Z",
          "shell.execute_reply": "2024-04-30T17:51:07.253777Z"
        },
        "trusted": true,
        "id": "EI512yYJb_n1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_best_final(model, data_loader, criterion, optimizer, device, batch_size):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    num_correct_train_char = 0\n",
        "\n",
        "    for inputs, target in data_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        crite_rion=0\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(inputs, target)\n",
        "        output = torch.permute(output, (1, 0, 2))\n",
        "        output3=crite_rion+1\n",
        "\n",
        "        output1 = output[1:].reshape(-1, output.shape[2])\n",
        "        target_vocab_size=58\n",
        "        target1 = target[1:].reshape(-1)\n",
        "        loss = criterion(output1, target1)\n",
        "        output3=crite_rion+1\n",
        "        loss.backward()\n",
        "        target_vocab_size=58\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss =train_loss + loss.item()\n",
        "        predict = F.softmax(output, dim=1)\n",
        "        predictionss = torch.argmax(predict, dim=2)\n",
        "        num_correct_train_char =  num_correct_train_char + (predictionss == target).sum().item()\n",
        "\n",
        "    train_accuracy_char = (num_correct_train_char/(len(data_loader)*batch_size*20))\n",
        "    train_accuracy_char=train_accuracy_char*100\n",
        "    train_loss = (train_loss/(len(data_loader)*batch_size))\n",
        "    train_loss=train_loss*100\n",
        "\n",
        "    return train_loss, train_accuracy_char"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:08.322703Z",
          "iopub.execute_input": "2024-04-30T17:51:08.323543Z",
          "iopub.status.idle": "2024-04-30T17:51:08.334880Z",
          "shell.execute_reply.started": "2024-04-30T17:51:08.323500Z",
          "shell.execute_reply": "2024-04-30T17:51:08.333821Z"
        },
        "trusted": true,
        "id": "asIfClD1b_n1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation function\n",
        "def evaluate_best_final(model, data_loader, criterion, device, batch_size , index_to_char_target):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_l_oss=[]\n",
        "    num_correct_val_char = 0\n",
        "    train_l_oss=[]\n",
        "    num_correct_val_word = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, target) in enumerate(data_test):\n",
        "            inputs=inputs.to(device)\n",
        "            crite_rion=0\n",
        "            target=target.to(device)\n",
        "\n",
        "            output = model.prediction(inputs)\n",
        "            output=torch.permute(output,(1,0,2))\n",
        "            output1=output[1:].reshape(-1,output.shape[2])\n",
        "            output2=crite_rion+1\n",
        "            target1=target[1:].reshape(-1)\n",
        "            loss = criterion(output1, target1)\n",
        "            val_loss = val_loss +  loss.item()\n",
        "\n",
        "            predictionss=torch.argmax(output,dim=2)\n",
        "            num_correct_val_char = num_correct_val_char + (predictionss == target).sum().item()\n",
        "\n",
        "            for j in range(len(predictionss)):\n",
        "              predicted_sentence = ''\n",
        "              target_sentence = ''\n",
        "              for k in range(len(predictionss[j])):\n",
        "                  if (predictionss[j][k].item()!=55):\n",
        "                    if(predictionss[j][k].item()!=56):\n",
        "                      if(predictionss[j][k].item()!=57):\n",
        "                        predicted_sentence = predicted_sentence + index_to_char_target[predictionss[j][k].item()]\n",
        "                  if (target[j][k].item()!=55):\n",
        "                    if(target[j][k].item()!=56):\n",
        "                      if(target[j][k].item()!=57):\n",
        "                        target_sentence = target_sentence +  index_to_char_target[target[j][k].item()]\n",
        "              if predicted_sentence==target_sentence:\n",
        "                  num_correct_val_word= num_correct_val_word + 1\n",
        "\n",
        "        val_accuracy_char=(num_correct_val_char/(len(data_test)*batch_size*20))\n",
        "        val_loss=(val_loss/(len(data_test)*batch_size))\n",
        "        val_accuracy_char=val_accuracy_char*100\n",
        "        val_loss=val_loss*100\n",
        "        val_accuracy_word=(num_correct_val_word/(len(data_test)*batch_size))\n",
        "        val_accuracy_word=val_accuracy_word*100\n",
        "\n",
        "    return val_loss, val_accuracy_char, val_accuracy_word"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:08.946860Z",
          "iopub.execute_input": "2024-04-30T17:51:08.947249Z",
          "iopub.status.idle": "2024-04-30T17:51:08.962476Z",
          "shell.execute_reply.started": "2024-04-30T17:51:08.947220Z",
          "shell.execute_reply": "2024-04-30T17:51:08.960556Z"
        },
        "trusted": true,
        "id": "arfse1ilb_n1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_best_model_final(config):\n",
        "\n",
        "    input_vocab_size=29\n",
        "    cell_type = config.cell_type\n",
        "\n",
        "    encoder_embedding_size = config.embedding_size\n",
        "    epochs = config.epochs\n",
        "    input_size_decoder=20\n",
        "    decoder_embedding_size = config.embedding_size\n",
        "    input_size_encoder=28\n",
        "\n",
        "    dec_dropout = config.dropout\n",
        "    num_encoder_layers = config.num_encoder_layer\n",
        "    learning_rate = config.learning_rate\n",
        "    num_decoder_layers = config.num_encoder_layer\n",
        "    output_vocab_size=55\n",
        "    enc_dropout = config.dropout\n",
        "    bidirection = config.bidirection\n",
        "    hidden_size = config.hidden_layer_size\n",
        "\n",
        "    run_name=\"ct_{}_ees_{}_lr_{}_des_{}_hs_{}_el_{}_dl_{}_ed_{}_dd_{}_bd_{}_ep_{}\".format(cell_type , encoder_embedding_size,learning_rate , decoder_embedding_size,hidden_size,num_encoder_layers,num_decoder_layers,enc_dropout,dec_dropout,bidirection, epochs)\n",
        "    # print(\"run_name:\",run_name)\n",
        "\n",
        "    encoder_net=encoder(input_size_encoder,encoder_embedding_size,hidden_size,num_encoder_layers,enc_dropout,input_vocab_size,bidirection,cell_type).to(device)\n",
        "    print(\"run_name:\",run_name)\n",
        "    decoder_net=Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_vocab_size,num_decoder_layers,dec_dropout,bidirection,cell_type).to(device)\n",
        "\n",
        "    # Create Seq2Seq model\n",
        "    model = seq2seq(encoder_net, decoder_net).to(device)\n",
        "    return model , run_name\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:09.396528Z",
          "iopub.execute_input": "2024-04-30T17:51:09.396901Z",
          "iopub.status.idle": "2024-04-30T17:51:09.406664Z",
          "shell.execute_reply.started": "2024-04-30T17:51:09.396864Z",
          "shell.execute_reply": "2024-04-30T17:51:09.405674Z"
        },
        "trusted": true,
        "id": "0KSXRQKZb_n1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop\n",
        "def train_loop_best_final(val_Acc_char , model, train_loader, val_loader, criterion, optimizer, device, config, index_to_char_target, run_name , batch_size , val_Acc_word ,train_Acc_char , val_Loss , train_Loss):\n",
        "\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        train_loss, train_accuracy_char = train_best_final(model, train_loader, criterion, optimizer, device , batch_size)\n",
        "        val_loss, val_accuracy_char, val_accuracy_word = evaluate_best_final(model, val_loader, criterion, device,batch_size, index_to_char_target)\n",
        "\n",
        "        train_Loss.append(train_loss)\n",
        "        train_Acc_char.append(train_accuracy_char)\n",
        "        val_Loss.append(val_loss)\n",
        "        val_Acc_char.append(val_accuracy_char)\n",
        "        val_Acc_word.append(val_accuracy_word)\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{config.epochs}]')\n",
        "\n",
        "        print(\"train_accuracy_char:\",train_accuracy_char)\n",
        "        print(\"train_loss:\",train_loss)\n",
        "        print(\"val_accuracy_word:\",val_accuracy_word)\n",
        "        print(\"val_loss:\", val_loss)\n",
        "        print(\"\")\n",
        "\n",
        "        # Logging using Weights & Biases\n",
        "        wandb_log_final(train_accuracy_char ,  train_loss , val_accuracy_word ,val_loss)\n",
        "\n",
        "\n",
        "    print(\"train_accuracy_char:\", np.max(train_Acc_char))\n",
        "    print(\"train_loss:\", np.min(train_Loss))\n",
        "    print(\"val_accuracy_word:\", np.max(val_Acc_word))\n",
        "    print(\"val_loss:\", np.min(val_Loss))\n",
        "\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "    wandb.run.finish()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:09.911569Z",
          "iopub.execute_input": "2024-04-30T17:51:09.912525Z",
          "iopub.status.idle": "2024-04-30T17:51:09.922960Z",
          "shell.execute_reply.started": "2024-04-30T17:51:09.912490Z",
          "shell.execute_reply": "2024-04-30T17:51:09.921780Z"
        },
        "trusted": true,
        "id": "liPH-71Lb_n2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_final():\n",
        "    initialize_wandb()\n",
        "    val_Acc_char=[]\n",
        "    batch_size = 64\n",
        "    val_Loss=[]\n",
        "    load_model = True\n",
        "    train_Acc_char=[]\n",
        "    config = wandb.config\n",
        "    model,run_name = build_best_model_final(config)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "    train_Loss=[]\n",
        "    best_accuracy=0\n",
        "    val_Acc_word = []\n",
        "    train_loop_best_final(val_Acc_char , model, data_train, data_val, criterion, optimizer, device, config, index_to_char_target, run_name , batch_size ,val_Acc_word , train_Acc_char , val_Loss , train_Loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:51:10.324211Z",
          "iopub.execute_input": "2024-04-30T17:51:10.325095Z",
          "iopub.status.idle": "2024-04-30T17:51:10.332038Z",
          "shell.execute_reply.started": "2024-04-30T17:51:10.325053Z",
          "shell.execute_reply": "2024-04-30T17:51:10.331114Z"
        },
        "trusted": true,
        "id": "dSU_jccBb_n2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id=wandb.sweep(sweep=sweep_configuration,entity=\"cs23m013\",project='DL_A3')\n",
        "wandb.agent(sweep_id,function=train_final,count=1)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-29T20:01:01.269679Z",
          "iopub.execute_input": "2024-04-29T20:01:01.269954Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822,
          "referenced_widgets": [
            "83420a0b66a54a3899771a164f017d6b",
            "392ac41f23bd4eda99450ba64e9be2a7",
            "18c7bca5d6a444509b8c928958a8a8f4",
            "835184e3447e4789a6be06ac9f0cacef",
            "d5d03173f06f49f8b4e9a58055c66490",
            "f4b85010f9f64b44b2ecd225f49fe6d6",
            "a48200d1be2c4973b8f062c6e12040d4",
            "56cb025121f0474d836230f3532cf5de"
          ]
        },
        "id": "6Y8ivfzdb_n2",
        "outputId": "a50b92a0-5e60-4f60-f014-e4084e5912db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: cj0xcstk\n",
            "Sweep URL: https://wandb.ai/cs23m013/DL_A3/sweeps/cj0xcstk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dz81ne61 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layer: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layer: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m013\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240501_102534-dz81ne61</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m013/DL_A3/runs/dz81ne61' target=\"_blank\">zesty-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m013/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m013/DL_A3/sweeps/cj0xcstk' target=\"_blank\">https://wandb.ai/cs23m013/DL_A3/sweeps/cj0xcstk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m013/DL_A3' target=\"_blank\">https://wandb.ai/cs23m013/DL_A3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m013/DL_A3/sweeps/cj0xcstk' target=\"_blank\">https://wandb.ai/cs23m013/DL_A3/sweeps/cj0xcstk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m013/DL_A3/runs/dz81ne61' target=\"_blank\">https://wandb.ai/cs23m013/DL_A3/runs/dz81ne61</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_name: ct_LSTM_ees_64_lr_1e-05_des_64_hs_128_el_2_dl_2_ed_0.6_dd_0.6_bd_False_ep_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1]\n",
            "train_accuracy_char: 50.536328125\n",
            "train_loss: 2.391900774324313\n",
            "val_accuracy_word: 0.0\n",
            "val_loss: 1.7054122494300827\n",
            "\n",
            "train_accuracy_char: 50.536328125\n",
            "train_loss: 2.391900774324313\n",
            "val_accuracy_word: 0.0\n",
            "val_loss: 1.7054122494300827\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83420a0b66a54a3899771a164f017d6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy_char</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_accuracy_word</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy_char</td><td>50.53633</td></tr><tr><td>train_loss</td><td>2.3919</td></tr><tr><td>val_accuracy_word</td><td>0.0</td></tr><tr><td>val_loss</td><td>1.70541</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">zesty-sweep-1</strong> at: <a href='https://wandb.ai/cs23m013/DL_A3/runs/dz81ne61' target=\"_blank\">https://wandb.ai/cs23m013/DL_A3/runs/dz81ne61</a><br/> View project at: <a href='https://wandb.ai/cs23m013/DL_A3' target=\"_blank\">https://wandb.ai/cs23m013/DL_A3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240501_102534-dz81ne61/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train with Best parameters"
      ],
      "metadata": {
        "id": "MvplqhNKvI0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_best(model, data_loader, criterion, optimizer, device, batch_size):\n",
        "#     model.train()\n",
        "#     train_loss = 0.0\n",
        "#     num_correct_train_char = 0\n",
        "\n",
        "#     for inputs, target in data_loader:\n",
        "#         inputs = inputs.to(device)\n",
        "#         target = target.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         output = model(inputs, target)\n",
        "#         output = torch.permute(output, (1, 0, 2))\n",
        "#         output1 = output[1:].reshape(-1, output.shape[2])\n",
        "\n",
        "#         target1 = target[1:].reshape(-1)\n",
        "\n",
        "#         loss = criterion(output1, target1)\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "#         optimizer.step()\n",
        "\n",
        "#         train_loss += loss.item()\n",
        "#         predict = F.softmax(output, dim=1)\n",
        "#         predictionss = torch.argmax(predict, dim=2)\n",
        "\n",
        "#         num_correct_train_char += (predictionss == target).sum().item()\n",
        "\n",
        "#     train_accuracy_char = (num_correct_train_char/(len(data_loader)*batch_size*20))*100\n",
        "#     train_loss = (train_loss/(len(data_loader)*batch_size))*100\n",
        "\n",
        "#     return train_loss, train_accuracy_char\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:52:40.018250Z",
          "iopub.execute_input": "2024-04-30T17:52:40.019189Z",
          "iopub.status.idle": "2024-04-30T17:52:40.029832Z",
          "shell.execute_reply.started": "2024-04-30T17:52:40.019141Z",
          "shell.execute_reply": "2024-04-30T17:52:40.028964Z"
        },
        "trusted": true,
        "id": "1usWJPScb_n2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Validation function\n",
        "# def evaluate_best(model, data_loader, criterion, device, batch_size , index_to_char_target):\n",
        "#     model.eval()\n",
        "#     val_loss = 0.0\n",
        "#     num_correct_val_char = 0\n",
        "#     num_correct_val_word = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, target) in enumerate(data_test):\n",
        "#             inputs=inputs.to(device)\n",
        "#             target=target.to(device)\n",
        "#             output = model.prediction(inputs)\n",
        "#             output=torch.permute(output,(1,0,2))\n",
        "#             output1=output[1:].reshape(-1,output.shape[2])\n",
        "#             target1=target[1:].reshape(-1)\n",
        "#             loss = criterion(output1, target1)\n",
        "#             val_loss += loss.item()\n",
        "#             predictionss=torch.argmax(output,dim=2)\n",
        "#             num_correct_val_char += (predictionss == target).sum().item()\n",
        "\n",
        "#             for j in range(len(predictionss)):\n",
        "#                 predicted_sentence = ''\n",
        "#                 target_sentence = ''\n",
        "#                 for k in range(len(predictionss[j])):\n",
        "#                     if (predictionss[j][k].item()!=55 and predictionss[j][k].item()!=56 and predictionss[j][k].item()!=57):\n",
        "#                         predicted_sentence += index_to_char_target[predictionss[j][k].item()]\n",
        "#                     if (target[j][k].item()!=55 and target[j][k].item()!=56 and target[j][k].item()!=57 ):\n",
        "#                         target_sentence += index_to_char_target[target[j][k].item()]\n",
        "#                 if predicted_sentence==target_sentence:\n",
        "#                     num_correct_val_word+=1\n",
        "\n",
        "#         val_loss=(val_loss/(len(data_test)*batch_size))*100\n",
        "#         val_accuracy_char=(num_correct_val_char/(len(data_test)*batch_size*20))*100\n",
        "#         val_accuracy_word=(num_correct_val_word/(len(data_test)*batch_size))*100\n",
        "\n",
        "#     return val_loss, val_accuracy_char, val_accuracy_word"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:52:42.696878Z",
          "iopub.execute_input": "2024-04-30T17:52:42.697691Z",
          "iopub.status.idle": "2024-04-30T17:52:42.710608Z",
          "shell.execute_reply.started": "2024-04-30T17:52:42.697660Z",
          "shell.execute_reply": "2024-04-30T17:52:42.709547Z"
        },
        "trusted": true,
        "id": "tNfuCBHgb_n2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def build_best_model():\n",
        "\n",
        "#     batch_size=64\n",
        "#     load_model=True\n",
        "#     epochs=5\n",
        "#     learning_rate=0.0001\n",
        "#     input_size_encoder=28\n",
        "#     input_size_decoder=20\n",
        "#     input_vocab_size=29\n",
        "#     output_vocab_size=55\n",
        "#     cell_type='GRU'\n",
        "#     encoder_embedding_size=256\n",
        "#     decoder_embedding_size=256\n",
        "#     hidden_size=512\n",
        "#     num_encoder_layers=3\n",
        "#     num_decoder_layers=3\n",
        "#     enc_dropout=0.3\n",
        "#     dec_dropout=0.3\n",
        "#     bidirection=True\n",
        "\n",
        "\n",
        "#     encoder_net=encoder(input_size_encoder,encoder_embedding_size,hidden_size,num_encoder_layers,enc_dropout,input_vocab_size,bidirection,cell_type).to(device)\n",
        "#     decoder_net=Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_vocab_size,num_decoder_layers,dec_dropout,bidirection,cell_type).to(device)\n",
        "\n",
        "#     # Create Seq2Seq model\n",
        "#     model = seq2seq(encoder_net, decoder_net).to(device)\n",
        "\n",
        "#     return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T17:52:54.419444Z",
          "iopub.execute_input": "2024-04-30T17:52:54.420122Z",
          "iopub.status.idle": "2024-04-30T17:52:54.427061Z",
          "shell.execute_reply.started": "2024-04-30T17:52:54.420088Z",
          "shell.execute_reply": "2024-04-30T17:52:54.426107Z"
        },
        "trusted": true,
        "id": "W1Kd_hiJb_n2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Main training loop\n",
        "# def train_loop_best(model, train_loader, val_loader, criterion, optimizer, device, index_to_char_target , best_accuracy):\n",
        "#     batch_size=64\n",
        "#     load_model=True\n",
        "#     epochs=1\n",
        "#     learning_rate=0.0001\n",
        "#     input_size_encoder=28\n",
        "#     input_size_decoder=20\n",
        "#     input_vocab_size=29\n",
        "#     output_vocab_size=55\n",
        "#     cell_type='GRU'\n",
        "#     encoder_embedding_size=256\n",
        "#     decoder_embedding_size=256\n",
        "#     hidden_size=512\n",
        "#     num_encoder_layers=3\n",
        "#     num_decoder_layers=3\n",
        "#     enc_dropout=0.3\n",
        "#     dec_dropout=0.3\n",
        "#     bidirection=True\n",
        "\n",
        "#     val_Loss = []\n",
        "#     train_Loss = []\n",
        "#     val_Acc_char = []\n",
        "#     val_Acc_word = []\n",
        "#     train_Acc_char = []\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         train_loss, train_accuracy_char = train_best(model, train_loader, criterion, optimizer, device , batch_size)\n",
        "#         val_loss, val_accuracy_char, val_accuracy_word = evaluate_best(model, val_loader, criterion, device,batch_size, index_to_char_target)\n",
        "\n",
        "#         train_Loss.append(train_loss)\n",
        "#         train_Acc_char.append(train_accuracy_char)\n",
        "#         val_Loss.append(val_loss)\n",
        "#         val_Acc_char.append(val_accuracy_char)\n",
        "#         val_Acc_word.append(val_accuracy_word)\n",
        "\n",
        "#         print(f'Epoch [{epoch + 1}/{epochs}]')\n",
        "\n",
        "#         print(\"train_accuracy_char:\",train_accuracy_char)\n",
        "#         print(\"train_loss:\",train_loss)\n",
        "#         print(\"val_accuracy_word:\",val_accuracy_word)\n",
        "#         print(\"val_loss:\", val_loss)\n",
        "#         print(\"\")\n",
        "\n",
        "#         if val_accuracy_char>best_accuracy:\n",
        "#             torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "#             model_wts=copy.deepcopy(model.state_dict())\n",
        "#             best_accuracy=val_accuracy_char\n",
        "\n",
        "\n",
        "#     print(\"train_accuracy_char:\", np.max(train_Acc_char))\n",
        "#     print(\"train_loss:\", np.min(train_Loss))\n",
        "#     print(\"val_accuracy_word:\", np.max(val_Acc_word))\n",
        "#     print(\"val_loss:\", np.min(val_Loss))\n",
        "\n",
        "#     plt.plot(train_Loss, 'r', label=\"Training loss\")\n",
        "#     plt.plot(val_Loss, 'lime', label=\"Validation loss\")\n",
        "#     plt.title(\"Training and Validation Loss vs Number of Epochs\", size=15)\n",
        "#     plt.xlabel(\"Number of epochs\", size=15)\n",
        "#     plt.ylabel(\"Loss\", size=15)\n",
        "#     plt.legend()\n",
        "#     plt.show()\n",
        "#     plt.plot(train_Acc_char, 'r', label=\"Training Accuracy char\")\n",
        "#     plt.plot(val_Acc_word ,'lime', label=\"Validation Accuracy word\")\n",
        "#     plt.plot(val_Acc_char ,'b', label=\"Validation Accuracy char\")\n",
        "#     plt.title(\"Training and Validation Accuracy vs Number of Epochs\", size=15)\n",
        "#     plt.xlabel(\"Number of epochs\", size=15)\n",
        "#     plt.ylabel(\"Accuracy\", size=15)\n",
        "#     plt.legend()\n",
        "#     plt.show()\n",
        "\n",
        "#     model.load_state_dict(model_wts)\n",
        "#     return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T19:06:52.219104Z",
          "iopub.execute_input": "2024-04-30T19:06:52.219465Z",
          "iopub.status.idle": "2024-04-30T19:06:52.235356Z",
          "shell.execute_reply.started": "2024-04-30T19:06:52.219436Z",
          "shell.execute_reply": "2024-04-30T19:06:52.234424Z"
        },
        "trusted": true,
        "id": "GxNCU_lfb_n2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_best_model():\n",
        "#     model = build_best_model()\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "#     criterion=nn.CrossEntropyLoss()\n",
        "#     best_accuracy=0\n",
        "#     return train_loop_best(model, data_train, data_val, criterion, optimizer, device, index_to_char_target , best_accuracy)"
      ],
      "metadata": {
        "id": "ugKLjHqErkYW",
        "execution": {
          "iopub.status.busy": "2024-04-30T19:06:59.461360Z",
          "iopub.execute_input": "2024-04-30T19:06:59.461726Z",
          "iopub.status.idle": "2024-04-30T19:06:59.467535Z",
          "shell.execute_reply.started": "2024-04-30T19:06:59.461686Z",
          "shell.execute_reply": "2024-04-30T19:06:59.466473Z"
        },
        "trusted": true
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_model=train_best_model()"
      ],
      "metadata": {
        "id": "URKTZi-2rkRv",
        "execution": {
          "iopub.status.busy": "2024-04-30T19:07:00.655123Z",
          "iopub.execute_input": "2024-04-30T19:07:00.655839Z",
          "iopub.status.idle": "2024-04-30T19:08:45.471719Z",
          "shell.execute_reply.started": "2024-04-30T19:07:00.655806Z",
          "shell.execute_reply": "2024-04-30T19:08:45.470614Z"
        },
        "trusted": true
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting word by trained model and saving in csv file"
      ],
      "metadata": {
        "id": "zl9CkH_arXqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction_out_list=[]\n",
        "# correct_prediction_out_list=[]\n",
        "\n",
        "# for i, (inputs, target) in enumerate(data_test):\n",
        "#     inputs=inputs.to(device)\n",
        "#     target=target.to(device)\n",
        "#     output = best_model.prediction(inputs)\n",
        "#     output=torch.permute(output,(1,0,2))\n",
        "#     predict=F.softmax(output,dim=1)\n",
        "#     predictionss=torch.argmax(predict,dim=2)\n",
        "\n",
        "#     for j in range(len(predictionss)):\n",
        "#         predicted_word = ''\n",
        "#         target_word = ''\n",
        "#         source_word=''\n",
        "\n",
        "#         for k in range(len(target[j])):\n",
        "#             if (target[j][k].item()!=55  and target[j][k].item()!=57):\n",
        "#                 if target[j][k].item()!=56:\n",
        "#                     target_word += index_to_char_target[target[j][k].item()]\n",
        "#                 else:\n",
        "#                     break\n",
        "\n",
        "#         for k in range(len(inputs[j])):\n",
        "#             if (inputs[j][k].item()!=26  and inputs[j][k].item()!=28):\n",
        "#                 if inputs[j][k].item()!=27:\n",
        "#                     source_word+=index_to_char_src[inputs[j][k].item()]\n",
        "#                 else:\n",
        "#                     break\n",
        "\n",
        "\n",
        "#         for k in range(len(predictionss[j])):\n",
        "#             if (predictionss[j][k].item()!=55  and predictionss[j][k].item()!=57):\n",
        "#                 if predictionss[j][k] != 56:\n",
        "#                     predicted_word += index_to_char_target[predictionss[j][k].item()]\n",
        "#                 else:\n",
        "#                     break\n",
        "\n",
        "#         prediction_out_list.append([source_word,predicted_word,target_word])\n",
        "\n",
        "#         if (predicted_word==target_word):\n",
        "#             correct_prediction_out_list.append([source_word,predicted_word,target_word])\n",
        "\n",
        "\n",
        "# #---------------------------\n",
        "\n",
        "# files= pd.DataFrame(np.array(prediction_out_list),columns = [\"Source\",\"Predicted\",\"Target\"])\n",
        "# files.to_csv(\"Prediction.csv\", index = False)\n",
        "\n",
        "# #----------------------------\n",
        "\n",
        "# # reading the csv file\n",
        "# cvsDataframe = pd.read_csv('Prediction.csv')\n",
        "\n",
        "# # creating an output excel file\n",
        "# resultExcelFile = pd.ExcelWriter('ResultExcelFile.xlsx')\n",
        "\n",
        "# # converting the csv file to an excel file\n",
        "# cvsDataframe.to_excel(resultExcelFile, index=False)\n",
        "\n",
        "# # saving the excel file\n",
        "# resultExcelFile.close()\n",
        "\n",
        "# # Reading and Converting the output/result excel file into a dataframe object\n",
        "# excelDataframe=pd.read_excel('ResultExcelFile.xlsx')\n",
        "\n",
        "# print(excelDataframe)\n",
        "\n"
      ],
      "metadata": {
        "id": "vkXIvDG1rkHr",
        "execution": {
          "iopub.status.busy": "2024-04-30T19:12:12.705020Z",
          "iopub.execute_input": "2024-04-30T19:12:12.705414Z",
          "iopub.status.idle": "2024-04-30T19:12:23.972472Z",
          "shell.execute_reply.started": "2024-04-30T19:12:12.705376Z",
          "shell.execute_reply": "2024-04-30T19:12:23.971441Z"
        },
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}